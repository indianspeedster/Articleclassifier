__label__cv Deep learning, in particular the deep convolutional neural networks, has received increasing interests in face recognition recently, and a number of deep learning methods have been proposed
__label__cv This paper summarizes about 330 contributions in this area
__label__cv It reviews major deep learning concepts pertinent to face image analysis and face recognition, and provides a concise overview of studies on specific face recognition problems, such as handling variations in pose, age, illumination, expression, and heterogeneous face matching
__label__cv A summary of databases used for deep face recognition is given as well
__label__cv Finally, some open challenges and directions are discussed for future research.
__label__cv Studies in biological vision have always been a great source of inspiration for design of computer vision algorithms
__label__cv In the past, several successful methods were designed with varying degrees of correspondence with biological vision studies, ranging from purely functional inspiration to methods that utilise models that were primarily developed for explaining biological observations
__label__cv Even though it seems well recognised that computational models of biological vision can help in design of computer vision algorithms, it is a non-trivial exercise for a computer vision researcher to mine relevant information from biological vision literature as very few studies in biology are organised at a task level
__label__cv In this paper we aim to bridge this gap by providing a computer vision task centric presentation of models primarily originating in biological vision studies
__label__cv Not only do we revisit some of the main features of biological vision and discuss the foundations of existing computational studies modelling biological vision, but also we consider three classical computer vision tasks from a biological perspective: image sensing, segmentation and optical flow
__label__cv Using this task-centric approach, we discuss well-known biological functional principles and compare them with approaches taken by computer vision
__label__cv Based on this comparative analysis of computer and biological vision, we present some recent models in biological vision and highlight a few models that we think are promising for future investigations in computer vision
__label__cv To this extent, this paper provides new insights and a starting point for investigators interested in the design of biology-based computer vision algorithms and pave a way for much needed interaction between the two communities leading to the development of synergistic models of artificial and biological vision.
__label__cv Head pose estimation (HPE) is currently a growing research field, mainly because of the proliferation of human–computer interfaces (HCI) in the last decade
__label__cv It offers a wide variety of applications, including human behavior analysis, driver assistance systems or gaze estimation systems
__label__cv This article aims to contribute to the development of robust and accurate HPE methods based on 2D tracking of the face, enhancing performance of both 2D point tracking and 3D pose estimation
__label__cv We start with a baseline method for pose estimation based on POSIT algorithm
__label__cv A novel weighted variant of POSIT is then proposed, together with a methodology to estimate weights for the 2D–3D point correspondences
__label__cv Further, outlier detection and correction methods are also proposed in order to enhance both point tracking and pose estimation
__label__cv With the aim of achieving a wider impact, the problem is addressed using a global approach: all the methods proposed are generalizable to any kind of object for which an approximate 3D model is available
__label__cv These methods have been evaluated for the specific task of HPE using two different head pose video databases; a recently published one that reflects the expected performance of the system in current technological conditions, and an older one that allows an extensive comparison with state-of-the-art HPE methods
__label__cv Results show that the proposed enhancements improve the accuracy of both 2D facial point tracking and 3D HPE, with respect to the implemented baseline method, by over 15% in normal tracking conditions and over 30% in noisy tracking conditions
__label__cv Moreover, the proposed HPE system outperforms the state of the art on the two databases.
__label__cv In this work we propose a novel approach to perform segmentation by leveraging the abstraction capabilities of convolutional neural networks (CNNs)
__label__cv Our method is based on Hough voting, a strategy that allows for fully automatic localisation and segmentation of the anatomies of interest
__label__cv This approach does not only use the CNN classification outcomes, but it also implements voting by exploiting the features produced by the deepest portion of the network
__label__cv We show that this learning-based segmentation method is robust, multi-region, flexible and can be easily adapted to different modalities
__label__cv In the attempt to show the capabilities and the behaviour of CNNs when they are applied to medical image analysis, we perform a systematic study of the performances of six different network architectures, conceived according to state-of-the-art criteria, in various situations
__label__cv We evaluate the impact of both different amount of training data and different data dimensionality (2D, 2.5D and 3D) on the final results
__label__cv We show results on both MRI and transcranial US volumes depicting respectively 26 regions of the basal ganglia and the midbrain.
__label__nlp You have gathered gigabytes or terabytes of unstructured text, for instance scraping the Internet, or pieces of email from your employees or users, or tweets, or millions of products that you want to categorize (only product description and product name is available - sometimes with typos)
__label__nlp Now you want to make sense of it, and extract value, possibly design a nice search engine so that your customers can easily find your products
__label__nlp The core algorithm that you need is an automated cataloguer, also called indexer
__label__nlp I am going to explain in layman's terms how it works
__label__nlp First, let's assume that the data consists ofpages or articles (a web page or the body of an email, etc.)subject lines (or page titles),and authors (for a web page or an email).Typically, these "pages" are stored as large repositories containing millions or billions of (sometimes compressed) text files spread across a number of folders and sub-folders, or multiple servers
__label__nlp Sometimes a time stamp is attached to each document, and can be leveraged to increase the accuracy of the indexer.Even if you only have pages (no user information, no titles), it will work
__label__nlp If you have pages and authors, you can classify the pages separately, then the authors separately (or in parallel), then blend the results to maximize accuracy
__label__nlp The same indexation algorithm (sometimes called tagging algorithm) is used in both cases
__label__nlp Despite the fact that classifying billions of documents seems mathematically unfeasible due to the computational complexity of traditional clustering algorithms (the time spent to cluster is growing much faster than linearly, as a function of the size of your repository), this algorithm is different, run very fast, and is easy to implement using a distributed architecture.The indexer algorithm creates a taxonomy of your pages (or products, articles, documents etc.) Each page is assigned a category and sub-category.Indexation algorithmStep 1: Create a data dictionary (that is, a frequency table) of all one-token and two-token keywords found in all pages (both in the title and in the body of the article)
__label__nlp This assumes that you crawled all your articles to extract all the text.Step 2: Filter / clean results
__label__nlp Ignore keywords with less than 5 occurrences
__label__nlp Check all n-grams of a keyword (data science and science data) and eliminate n-grams with low frequency, for each keywordStep 3: Look at top 300 entries, called seed keywords
__label__nlp Manually assign seed keywords to 10-20 categories, (these categories are manually pre-selected, after looking at the top 300 entries.) For instance, the top category data plumbing will have the following seed keywords: data engineer, data architect, data warehouse, Hadoop, Spark, data lakes, IoT and many more
__label__nlp Don't forget to have a top category called Unknown.Step 4
__label__nlp Based on keywords found in the title and body of an article, assign the article in question to the top category that has the biggest overlap with the article, in terms of seed keywords
__label__nlp Note that keywords found in the title might be assigned a higher weight than those found in the body
__label__nlp Likewise, a different weight can be attached to each seed keyword, in each top category.I call this technique indexation because it is very similar to the creation of a search engine
__label__nlp We also have used and described this technique in the context of clustering thousands of data science websites (source code provided)
__label__nlp This is a must-read article to get a better idea of the technical implementation.Potential improvementThese improvements will improve the performance (accuracy).Add 3-token keywords in your dictionary, not just 1- and 2-token
__label__nlp For 3 tokens keywords, you have 3! (factorial 3) = 6 n-grams
__label__nlp Usually, only one or two of these 6 n-grams will show up in the articles, for any keyword (data science central will show up, but central science data won't).Use stop words to clean your data
__label__nlp Examples: it, where, how, why, for and so on
__label__nlp Be careful though: IT Job can not be reduced to Job by filtering out the token IT
__label__nlp You can replace plurals by singular, and normalize the keywords..Some one-token words don't make sense
__label__nlp Do not break San Francisco in San and Francisco
__label__nlp Used a table of keywords that should not be split.Even without improvements, the methodology will work well, because you focus on top keywords in terms of frequency
__label__nlp For instance, in Best San Francisco Hotels, the keywords Best San and Francisco Hotels won't show up at the top, and if they do, you can remove them, as you manually review the top 3,000 entries (a process that takes 30 minutes).Finally, the last search engine company I worked for relied on the BerkeleyDB open source software (combined with a bunch of lookup tables such as stop keywords, synonyms and so on) to do many of these tasks
__label__nlp Though it just take a few hours to write your own code.About the author:Vincent Granville worked for Visa, eBay, Microsoft, Wells Fargo, NBC, a few startups and various organizations, to optimize business problems, boost ROI or to develop ROI attribution models, developing new techniques and systems to leverage modern big data and deliver added value
__label__nlp Vincent owns several patents, published in top scientific journals, raised VC funding, and founded a few startups
__label__nlp Vincent also manages his own self-funded research lab, focusing on simplifying, unifying, modernizing, automating, scaling, and dramatically optimizing statistical techniques
__label__nlp Vincent's focus is on producing robust, automatable tools, API's and algorithms that can be used and understood by the layman, and at the same time adapted to modern big, fast-flowing, unstructured data
__label__nlp Vincent is a post-graduate from Cambridge University.DSC ResourcesAdditional ReadingFollow us on Twitter: @DataScienceCtrl | @AnalyticBridge
__label__nlp Use Cases of NLPIn simple terms, NLP represents the automatic handling of natural human language like speech or text, and although the concept itself is fascinating, the real value behind this technology comes from the use cases.NLP can help you with lots of tasks and the fields of application just seem to increase on a daily basis
__label__nlp Let’s mention some examples:NLP enables the recognition and prediction of diseases based on electronic health records and patient’s own speech
__label__nlp This capability is being explored in health conditions that go from cardiovascular diseases to depression and even schizophrenia
__label__nlp For example, Amazon Comprehend Medical is a service that uses NLP to extract disease conditions, medications and treatment outcomes from patient notes, clinical trial reports and other electronic health records.based on electronic health records and patient’s own speech
__label__nlp This capability is being explored in health conditions that go from cardiovascular diseases to depression and even schizophrenia
__label__nlp For example, Amazon Comprehend Medical is a service that uses NLP to extract disease conditions, medications and treatment outcomes from patient notes, clinical trial reports and other electronic health records
__label__nlp Organizations can determine what customers are saying about a service or product by identifying and extracting information in sources like social media
__label__nlp This sentiment analysis can provide a lot of information about customers choices and their decision drivers.can provide a lot of information about customers choices and their decision drivers
__label__nlp An inventor at IBM developed a cognitive assistant that works like a personalized search engine by learning all about you and then remind you of a name, a song, or anything you can’t remember the moment you need it to.that works like a personalized search engine by learning all about you and then remind you of a name, a song, or anything you can’t remember the moment you need it to
__label__nlp Companies like Yahoo and Google filter and classify your emails with NLP by analyzing text in emails that flow through their servers and stopping spam before they even enter your inbox.before they even enter your inbox
__label__nlp To help identifying fake news , the NLP Group at MIT developed a new system to determine if a source is accurate or politically biased, detecting if a news source can be trusted or not., the NLP Group at MIT developed a new system to determine if a source is accurate or politically biased, detecting if a news source can be trusted or not
__label__nlp Amazon’s Alexa and Apple’s Siri are examples of intelligent voice driven interfaces that use NLP to respond to vocal prompts and do everything like find a particular shop, tell us the weather forecast, suggest the best route to the office or turn on the lights at home.that use NLP to respond to vocal prompts and do everything like find a particular shop, tell us the weather forecast, suggest the best route to the office or turn on the lights at home
__label__nlp Having an insight into what is happening and what people are talking about can be very valuable to financial traders 
__label__nlp NLP is being used to track news, reports, comments about possible mergers between companies, everything can be then incorporated into a trading algorithm to generate massive profits
__label__nlp Remember: buy the rumor, sell the news.
__label__nlp NLP is being used to track news, reports, comments about possible mergers between companies, everything can be then incorporated into a trading algorithm to generate massive profits
__label__nlp Remember: buy the rumor, sell the news
__label__nlp NLP is also being used in both the search and selection phases of talent recruitment , identifying the skills of potential hires and also spotting prospects before they become active on the job market., identifying the skills of potential hires and also spotting prospects before they become active on the job market
__label__nlp Powered by IBM Watson NLP technology, LegalMation developed a platform to automate routine litigation tasks and help legal teams save time, drive down costs and shift strategic focus.NLP is particularly booming in the healthcare industry
__label__nlp This technology is improving care delivery, disease diagnosis and bringing costs down while healthcare organizations are going through a growing adoption of electronic health records
__label__nlp The fact that clinical documentation can be improved means that patients can be better understood and benefited through better healthcare
__label__nlp The goal should be to optimize their experience, and several organizations are already working on this.Number of publications containing the sentence “natural language processing” in PubMed in the period 1978–2018
__label__nlp As of 2018, PubMed comprised more than 29 million citations for biomedical literatureCompanies like Winterlight Labs are making huge improvements in the treatment of Alzheimer’s disease by monitoring cognitive impairment through speech and they can also support clinical trials and studies for a wide range of central nervous system disorders
__label__nlp Following a similar approach, Stanford University developed Woebot, a chatbot therapist with the aim of helping people with anxiety and other disorders.But serious controversy is around the subject
__label__nlp A couple of years ago Microsoft demonstrated that by analyzing large samples of search engine queries, they could identify internet users who were suffering from pancreatic cancer even before they have received a diagnosis of the disease
__label__nlp How would users react to such diagnosis? And what would happen if you were tested as a false positive? (meaning that you can be diagnosed with the disease even though you don’t have it)
__label__nlp This recalls the case of Google Flu Trends which in 2009 was announced as being able to predict influenza but later on vanished due to its low accuracy and inability to meet its projected rates.NLP may be the key to an effective clinical support in the future, but there are still many challenges to face in the short term.Basic NLP to impress your non-NLP friendsThe main drawbacks we face these days with NLP relate to the fact that language is very tricky
__label__nlp The process of understanding and manipulating language is extremely complex, and for this reason it is common to use different techniques to handle different challenges before binding everything together
__label__nlp Programming languages like Python or R are highly used to perform these techniques, but before diving into code lines (that will be the topic of a different article), it’s important to understand the concepts beneath them
__label__nlp Let’s summarize and explain some of the most frequently used algorithms in NLP when defining the vocabulary of terms:Bag of WordsIs a commonly used model that allows you to count all words in a piece of text
__label__nlp Basically it creates an occurrence matrix for the sentence or document, disregarding grammar and word order
__label__nlp These word frequencies or occurrences are then used as features for training a classifier.To bring a short example I took the first sentence of the song “Across the Universe” from The Beatles:Words are flowing out like endless rain into a paper cup,They slither while they pass, they slip away across the universeNow let’s count the words:This approach may reflect several downsides like the absence of semantic meaning and context, and the facts that stop words (like “the” or “a”) add noise to the analysis and some words are not weighted accordingly (“universe” weights less than the word “they”).To solve this problem, one approach is to rescale the frequency of words by how often they appear in all texts (not just the one we are analyzing) so that the scores for frequent words like “the”, that are also frequent across other texts, get penalized
__label__nlp This approach to scoring is called “Term Frequency — Inverse Document Frequency” (TFIDF), and improves the bag of words by weights
__label__nlp Through TFIDF frequent terms in the text are “rewarded” (like the word “they” in our example), but they also get “punished” if those terms are frequent in other texts we include in the algorithm too
__label__nlp On the contrary, this method highlights and “rewards” unique or rare terms considering all texts
__label__nlp Nevertheless, this approach still has no context nor semantics.TokenizationIs the process of segmenting running text into sentences and words
__label__nlp In essence, it’s the task of cutting a text into pieces called tokens, and at the same time throwing away certain characters, such as punctuation
__label__nlp Following our example, the result of tokenization would be:Pretty simple, right? Well, although it may seem quite basic in this case and also in languages like English that separate words by a blank space (called segmented languages) not all languages behave the same, and if you think about it, blank spaces alone are not sufficient enough even for English to perform proper tokenizations
__label__nlp Splitting on blank spaces may break up what should be considered as one token, as in the case of certain names (e.g
__label__nlp San Francisco or New York) or borrowed foreign phrases (e.g
__label__nlp laissez faire).Tokenization can remove punctuation too, easing the path to a proper word segmentation but also triggering possible complications
__label__nlp In the case of periods that follow abbreviation (e.g
__label__nlp dr.), the period following that abbreviation should be considered as part of the same token and not be removed.The tokenization process can be particularly problematic when dealing with biomedical text domains which contain lots of hyphens, parentheses, and other punctuation marks.For deeper details on tokenization, you can find a great explanation in this article.Stop Words RemovalIncludes getting rid of common language articles, pronouns and prepositions such as “and”, “the” or “to” in English
__label__nlp In this process some very common words that appear to provide little or no value to the NLP objective are filtered and excluded from the text to be processed, hence removing widespread and frequent terms that are not informative about the corresponding text.Stop words can be safely ignored by carrying out a lookup in a pre-defined list of keywords, freeing up database space and improving processing time.There is no universal list of stop words
__label__nlp These can be pre-selected or built from scratch
__label__nlp A potential approach is to begin by adopting pre-defined stop words and add words to the list later on
__label__nlp Nevertheless it seems that the general trend over the past time has been to go from the use of large standard stop word lists to the use of no lists at all.The thing is stop words removal can wipe out relevant information and modify the context in a given sentence
__label__nlp For example, if we are performing a sentiment analysis we might throw our algorithm off track if we remove a stop word like “not”
__label__nlp Under these conditions, you might select a minimal stop word list and add additional terms depending on your specific objective.Stemmingrefers to the process of slicing the end or the beginning of words with the intention of removing affixes (lexical additions to the root of the word).Affixes that are attached at the beginning of the word are called prefixes (e.g
__label__nlp “astro” in the word “astrobiology”) and the ones attached at the end of the word are called suffixes (e.g
__label__nlp “ful” in the word “helpful”).The problem is that affixes can create or expand new forms of the same word (called inflectional affixes), or even create new words themselves (called derivational affixes)
__label__nlp In English, prefixes are always derivational (the affix creates a new word as in the example of the prefix “eco” in the word “ecosystem”), but suffixes can be derivational (the affix creates a new word as in the example of the suffix “ist” in the word “guitarist”) or inflectional (the affix creates a new form of word as in the example of the suffix “er” in the word “faster”).Ok, so how can we tell the difference and chop the right bit?A possible approach is to consider a list of common affixes and rules (Python and R languages have different libraries containing affixes and methods) and perform stemming based on them, but of course this approach presents limitations
__label__nlp Since stemmers use algorithmics approaches, the result of the stemming process may not be an actual word or even change the word (and sentence) meaning
__label__nlp To offset this effect you can edit those predefined methods by adding or removing affixes and rules, but you must consider that you might be improving the performance in one area while producing a degradation in another one
__label__nlp Always look at the whole picture and test your model’s performance.So if stemming has serious limitations, why do we use it? First of all, it can be used to correct spelling errors from the tokens
__label__nlp Stemmers are simple to use and run very fast (they perform simple operations on a string), and if speed and performance are important in the NLP model, then stemming is certainly the way to go
__label__nlp Remember, we use it with the objective of improving our performance, not as a grammar exercise.LemmatizationHas the objective of reducing a word to its base form and grouping together different forms of the same word
__label__nlp For example, verbs in past tense are changed into present (e.g
__label__nlp “went” is changed to “go”) and synonyms are unified (e.g
__label__nlp “best” is changed to “good”), hence standardizing words with similar meaning to their root
__label__nlp Although it seems closely related to the stemming process, lemmatization uses a different approach to reach the root forms of words.Lemmatization resolves words to their dictionary form (known as lemma) for which it requires detailed dictionaries in which the algorithm can look into and link words to their corresponding lemmas.For example, the words “running”, “runs” and “ran” are all forms of the word “run”, so “run” is the lemma of all the previous words.Lemmatization also takes into consideration the context of the word in order to solve other problems like disambiguation, which means it can discriminate between identical words that have different meanings depending on the specific context
__label__nlp Think about words like “bat” (which can correspond to the animal or to the metal/wooden club used in baseball) or “bank” (corresponding to the financial institution or to the land alongside a body of water)
__label__nlp By providing a part-of-speech parameter to a word ( whether it is a noun, a verb, and so on) it’s possible to define a role for that word in the sentence and remove disambiguation.As you might already pictured, lemmatization is a much more resource-intensive task than performing a stemming process
__label__nlp At the same time, since it requires more knowledge about the language structure than a stemming approach, it demands more computational power than setting up or adapting a stemming algorithm.Topic ModelingIs as a method for uncovering hidden structures in sets of texts or documents
__label__nlp In essence it clusters texts to discover latent topics based on their contents, processing individual words and assigning them values based on their distribution
__label__nlp This technique is based on the assumptions that each document consists of a mixture of topics and that each topic consists of a set of words, which means that if we can spot these hidden topics we can unlock the meaning of our texts.From the universe of topic modelling techniques, Latent Dirichlet Allocation (LDA) is probably the most commonly used
__label__nlp This relatively new algorithm (invented less than 20 years ago) works as an unsupervised learning method that discovers different topics underlying a collection of documents
__label__nlp In unsupervised learning methods like this one, there is no output variable to guide the learning process and data is explored by algorithms to find patterns
__label__nlp To be more specific, LDA finds groups of related words by:Assigning each word to a random topic, where the user defines the number of topics it wishes to uncover
__label__nlp You don’t define the topics themselves (you define just the number of topics) and the algorithm will map all documents to the topics in a way that words in each document are mostly captured by those imaginary topics
__label__nlp The algorithm goes through each word iteratively and reassigns the word to a topic taking into considerations the probability that the word belongs to a topic, and the probability that the document will be generated by a topic
__label__nlp These probabilities are calculated multiple times, until the convergence of the algorithm.Unlike other clustering algorithms like K-means that perform hard clustering (where topics are disjointed), LDA assigns each document to a mixture of topics, which means that each document can be described by one or more topics (e.g
__label__nlp Document 1 is described by 70% of topic A, 20% of topic B and 10% of topic C) and reflect more realistic results.Topic modeling is extremely useful for classifying texts, building recommender systems (e.g
__label__nlp to recommend you books based on your past readings) or even detecting trends in online publications.How does the future look like?At the moment NLP is battling to detect nuances in language meaning, whether due to lack of context, spelling errors or dialectal differences.On March 2016 Microsoft launched Tay, an Artificial Intelligence (AI) chatbot released on Twitter as a NLP experiment
__label__nlp The idea was that as more users conversed with Tay, the smarter it would get
__label__nlp Well, the result was that after 16 hours Tay had to be removed due to its racist and abusive comments:Microsoft learnt from its own experience and some months later released Zo, its second generation English-language chatbot that won’t be caught making the same mistakes as its predecessor
__label__nlp Zo uses a combination of innovative approaches to recognize and generate conversation, and other companies are exploring with bots that can remember details specific to an individual conversation.Although the future looks extremely challenging and full of threats for NLP, the discipline is developing at a very fast pace (probably like never before) and we are likely to reach a level of advancement in the coming years that will make complex applications look possible.
__label__cv Deep learning, in particular the deep convolutional neural networks, has received increasing interests in face recognition recently, and a number of deep learning methods have been proposed
__label__cv This paper summarizes about 330 contributions in this area
__label__cv It reviews major deep learning concepts pertinent to face image analysis and face recognition, and provides a concise overview of studies on specific face recognition problems, such as handling variations in pose, age, illumination, expression, and heterogeneous face matching
__label__cv A summary of databases used for deep face recognition is given as well
__label__cv Finally, some open challenges and directions are discussed for future research.
__label__cv Studies in biological vision have always been a great source of inspiration for design of computer vision algorithms
__label__cv In the past, several successful methods were designed with varying degrees of correspondence with biological vision studies, ranging from purely functional inspiration to methods that utilise models that were primarily developed for explaining biological observations
__label__cv Even though it seems well recognised that computational models of biological vision can help in design of computer vision algorithms, it is a non-trivial exercise for a computer vision researcher to mine relevant information from biological vision literature as very few studies in biology are organised at a task level
__label__cv In this paper we aim to bridge this gap by providing a computer vision task centric presentation of models primarily originating in biological vision studies
__label__cv Not only do we revisit some of the main features of biological vision and discuss the foundations of existing computational studies modelling biological vision, but also we consider three classical computer vision tasks from a biological perspective: image sensing, segmentation and optical flow
__label__cv Using this task-centric approach, we discuss well-known biological functional principles and compare them with approaches taken by computer vision
__label__cv Based on this comparative analysis of computer and biological vision, we present some recent models in biological vision and highlight a few models that we think are promising for future investigations in computer vision
__label__cv To this extent, this paper provides new insights and a starting point for investigators interested in the design of biology-based computer vision algorithms and pave a way for much needed interaction between the two communities leading to the development of synergistic models of artificial and biological vision.
__label__cv Head pose estimation (HPE) is currently a growing research field, mainly because of the proliferation of human–computer interfaces (HCI) in the last decade
__label__cv It offers a wide variety of applications, including human behavior analysis, driver assistance systems or gaze estimation systems
__label__cv This article aims to contribute to the development of robust and accurate HPE methods based on 2D tracking of the face, enhancing performance of both 2D point tracking and 3D pose estimation
__label__cv We start with a baseline method for pose estimation based on POSIT algorithm
__label__cv A novel weighted variant of POSIT is then proposed, together with a methodology to estimate weights for the 2D–3D point correspondences
__label__cv Further, outlier detection and correction methods are also proposed in order to enhance both point tracking and pose estimation
__label__cv With the aim of achieving a wider impact, the problem is addressed using a global approach: all the methods proposed are generalizable to any kind of object for which an approximate 3D model is available
__label__cv These methods have been evaluated for the specific task of HPE using two different head pose video databases; a recently published one that reflects the expected performance of the system in current technological conditions, and an older one that allows an extensive comparison with state-of-the-art HPE methods
__label__cv Results show that the proposed enhancements improve the accuracy of both 2D facial point tracking and 3D HPE, with respect to the implemented baseline method, by over 15% in normal tracking conditions and over 30% in noisy tracking conditions
__label__cv Moreover, the proposed HPE system outperforms the state of the art on the two databases.
__label__cv In this work we propose a novel approach to perform segmentation by leveraging the abstraction capabilities of convolutional neural networks (CNNs)
__label__cv Our method is based on Hough voting, a strategy that allows for fully automatic localisation and segmentation of the anatomies of interest
__label__cv This approach does not only use the CNN classification outcomes, but it also implements voting by exploiting the features produced by the deepest portion of the network
__label__cv We show that this learning-based segmentation method is robust, multi-region, flexible and can be easily adapted to different modalities
__label__cv In the attempt to show the capabilities and the behaviour of CNNs when they are applied to medical image analysis, we perform a systematic study of the performances of six different network architectures, conceived according to state-of-the-art criteria, in various situations
__label__cv We evaluate the impact of both different amount of training data and different data dimensionality (2D, 2.5D and 3D) on the final results
__label__cv We show results on both MRI and transcranial US volumes depicting respectively 26 regions of the basal ganglia and the midbrain.
__label__cv Deep learning, in particular the deep convolutional neural networks, has received increasing interests in face recognition recently, and a number of deep learning methods have been proposed
__label__cv This paper summarizes about 330 contributions in this area
__label__cv It reviews major deep learning concepts pertinent to face image analysis and face recognition, and provides a concise overview of studies on specific face recognition problems, such as handling variations in pose, age, illumination, expression, and heterogeneous face matching
__label__cv A summary of databases used for deep face recognition is given as well
__label__cv Finally, some open challenges and directions are discussed for future research.
__label__cv Studies in biological vision have always been a great source of inspiration for design of computer vision algorithms
__label__cv In the past, several successful methods were designed with varying degrees of correspondence with biological vision studies, ranging from purely functional inspiration to methods that utilise models that were primarily developed for explaining biological observations
__label__cv Even though it seems well recognised that computational models of biological vision can help in design of computer vision algorithms, it is a non-trivial exercise for a computer vision researcher to mine relevant information from biological vision literature as very few studies in biology are organised at a task level
__label__cv In this paper we aim to bridge this gap by providing a computer vision task centric presentation of models primarily originating in biological vision studies
__label__cv Not only do we revisit some of the main features of biological vision and discuss the foundations of existing computational studies modelling biological vision, but also we consider three classical computer vision tasks from a biological perspective: image sensing, segmentation and optical flow
__label__cv Using this task-centric approach, we discuss well-known biological functional principles and compare them with approaches taken by computer vision
__label__cv Based on this comparative analysis of computer and biological vision, we present some recent models in biological vision and highlight a few models that we think are promising for future investigations in computer vision
__label__cv To this extent, this paper provides new insights and a starting point for investigators interested in the design of biology-based computer vision algorithms and pave a way for much needed interaction between the two communities leading to the development of synergistic models of artificial and biological vision.
__label__cv Head pose estimation (HPE) is currently a growing research field, mainly because of the proliferation of human–computer interfaces (HCI) in the last decade
__label__cv It offers a wide variety of applications, including human behavior analysis, driver assistance systems or gaze estimation systems
__label__cv This article aims to contribute to the development of robust and accurate HPE methods based on 2D tracking of the face, enhancing performance of both 2D point tracking and 3D pose estimation
__label__cv We start with a baseline method for pose estimation based on POSIT algorithm
__label__cv A novel weighted variant of POSIT is then proposed, together with a methodology to estimate weights for the 2D–3D point correspondences
__label__cv Further, outlier detection and correction methods are also proposed in order to enhance both point tracking and pose estimation
__label__cv With the aim of achieving a wider impact, the problem is addressed using a global approach: all the methods proposed are generalizable to any kind of object for which an approximate 3D model is available
__label__cv These methods have been evaluated for the specific task of HPE using two different head pose video databases; a recently published one that reflects the expected performance of the system in current technological conditions, and an older one that allows an extensive comparison with state-of-the-art HPE methods
__label__cv Results show that the proposed enhancements improve the accuracy of both 2D facial point tracking and 3D HPE, with respect to the implemented baseline method, by over 15% in normal tracking conditions and over 30% in noisy tracking conditions
__label__cv Moreover, the proposed HPE system outperforms the state of the art on the two databases.
__label__cv In this work we propose a novel approach to perform segmentation by leveraging the abstraction capabilities of convolutional neural networks (CNNs)
__label__cv Our method is based on Hough voting, a strategy that allows for fully automatic localisation and segmentation of the anatomies of interest
__label__cv This approach does not only use the CNN classification outcomes, but it also implements voting by exploiting the features produced by the deepest portion of the network
__label__cv We show that this learning-based segmentation method is robust, multi-region, flexible and can be easily adapted to different modalities
__label__cv In the attempt to show the capabilities and the behaviour of CNNs when they are applied to medical image analysis, we perform a systematic study of the performances of six different network architectures, conceived according to state-of-the-art criteria, in various situations
__label__cv We evaluate the impact of both different amount of training data and different data dimensionality (2D, 2.5D and 3D) on the final results
__label__cv We show results on both MRI and transcranial US volumes depicting respectively 26 regions of the basal ganglia and the midbrain.
